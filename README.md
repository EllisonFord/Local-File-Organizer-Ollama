# Local File Organizer: AI File Management Run Entirely on Your Device, Privacy Assured

Tired of digital clutter? Overwhelmed by disorganized files scattered across your computer? Let AI do the heavy lifting! The Local File Organizer is your personal organizing assistant, using cutting-edge AI to bring order to your file chaos - all while respecting your privacy.

## How It Works üí°

Before:

```
/home/user/messy_documents/
‚îú‚îÄ‚îÄ IMG_20230515_140322.jpg
‚îú‚îÄ‚îÄ IMG_20230516_083045.jpg
‚îú‚îÄ‚îÄ IMG_20230517_192130.jpg
‚îú‚îÄ‚îÄ budget_2023.xlsx
‚îú‚îÄ‚îÄ meeting_notes_05152023.txt
‚îú‚îÄ‚îÄ project_proposal_draft.docx
‚îú‚îÄ‚îÄ random_thoughts.txt
‚îú‚îÄ‚îÄ recipe_chocolate_cake.pdf
‚îú‚îÄ‚îÄ scan0001.pdf
‚îú‚îÄ‚îÄ vacation_itinerary.docx
‚îî‚îÄ‚îÄ work_presentation.pptx

0 directories, 11 files
```

After:

```
/home/user/organized_documents/
‚îú‚îÄ‚îÄ Financial
‚îÇ   ‚îî‚îÄ‚îÄ 2023_Budget_Spreadsheet.xlsx
‚îú‚îÄ‚îÄ Food_and_Recipes
‚îÇ   ‚îî‚îÄ‚îÄ Chocolate_Cake_Recipe.pdf
‚îú‚îÄ‚îÄ Meetings_and_Notes
‚îÇ   ‚îî‚îÄ‚îÄ Team_Meeting_Notes_May_15_2023.txt
‚îú‚îÄ‚îÄ Personal
‚îÇ   ‚îî‚îÄ‚îÄ Random_Thoughts_and_Ideas.txt
‚îú‚îÄ‚îÄ Photos
‚îÇ   ‚îú‚îÄ‚îÄ Cityscape_Sunset_May_17_2023.jpg
‚îÇ   ‚îú‚îÄ‚îÄ Morning_Coffee_Shop_May_16_2023.jpg
‚îÇ   ‚îî‚îÄ‚îÄ Office_Team_Lunch_May_15_2023.jpg
‚îú‚îÄ‚îÄ Travel
‚îÇ   ‚îî‚îÄ‚îÄ Summer_Vacation_Itinerary_2023.docx
‚îî‚îÄ‚îÄ Work
    ‚îú‚îÄ‚îÄ Project_X_Proposal_Draft.docx
    ‚îú‚îÄ‚îÄ Quarterly_Sales_Report.pdf
    ‚îî‚îÄ‚îÄ Marketing_Strategy_Presentation.pptx

7 directories, 11 files
```

## Updates üöÄ

**[2024/09] v0.0.2**:
* Featured by [Nexa Gallery](https://nexaai.com/gallery) and [Nexa SDK Cookbook](https://github.com/NexaAI/nexa-sdk/tree/main/examples)!
* Dry Run Mode: check sorting results before committing changes
* Silent Mode: save all logs to a txt file for quieter operation
* Added file support:  `.md`, .`excel`, `.ppt`, and `.csv` 
* Three sorting options: by content, by date, and by type
* The default text model is now [Llama3.2 3B](https://nexaai.com/meta/Llama3.2-3B-Instruct/gguf-q3_K_M/file)
* Improved CLI interaction experience
* Added real-time progress bar for file analysis

Please update the project by deleting the original project folder and reinstalling the requirements. Refer to the installation guide from Step 4.


## Roadmap üìÖ

- [ ] Copilot Mode: chat with AI to tell AI how you want to sort the file (ie. read and rename all the PDFs)
- [ ] Change models with CLI 
- [ ] ebook format support
- [ ] audio file support
- [ ] video file support
- [ ] Implement best practices like Johnny Decimal
- [ ] Check file duplication
- [ ] Dockerfile for easier installation
- [ ] People from [Nexa](https://github.com/NexaAI/nexa-sdk) is helping me to make executables for macOS, Linux and Windows

## What It Does üîç

This intelligent file organizer harnesses the power of advanced AI models, including language models (LMs) and vision-language models (VLMs), to automate the process of organizing files by:


* Scanning a specified input directory for files.
* Content Understanding: 
  - **Textual Analysis**: Uses the [Llama3.2 3B](https://nexaai.com/meta/Llama3.2-3B-Instruct/gguf-q3_K_M/file) to analyze and summarize text-based content, generating relevant descriptions and filenames.
  - **Visual Content Analysis**: Uses the [LLaVA-v1.6](https://nexaai.com/liuhaotian/llava-v1.6-vicuna-7b/gguf-q4_0/file) , based on Vicuna-7B, to interpret visual files such as images, providing context-aware categorization and descriptions.

* Understanding the content of your files (text, images, and more) to generate relevant descriptions, folder names, and filenames.
* Organizing the files into a new directory structure based on the generated metadata.

The best part? All AI processing happens 100% on your local device using [Ollama](https://ollama.com/) running locally. No internet connection required, no data leaves your computer, and no external AI API keys are needed ‚Äî keeping your files completely private and secure.


## Supported File Types üìÅ

- **Images:** `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`
- **Text Files:** `.txt`, `.docx`, `.md`
- **Spreadsheets:** `.xlsx`, `.csv`
- **Presentations:** `.ppt`, `.pptx`
- **PDFs:** `.pdf`

## Prerequisites üíª

- **Operating System:** Compatible with Windows, macOS, and Linux.
- **Python Version:** Python 3.12
- **Conda:** Anaconda or Miniconda installed.
- **Git:** For cloning the repository (or you can download the code as a ZIP file).

## Installation üõ†

> For SDK installation and model-related issues, please post on [here](https://github.com/NexaAI/nexa-sdk/issues).

### 1. Install Python

Before installing the Local File Organizer, make sure you have Python installed on your system. We recommend using Python 3.12 or later.

You can download Python from [the official website]((https://www.python.org/downloads/)).

Follow the installation instructions for your operating system.

### 2. Clone the Repository

Clone this repository to your local machine using Git:

```zsh
git clone https://github.com/QiuYannnn/Local-File-Organizer.git
```

Or download the repository as a ZIP file and extract it to your desired location.

### 3. Set Up the Python Environment

Create a new Conda environment named `local_file_organizer` with Python 3.12:

```zsh
conda create --name local_file_organizer python=3.12
```

Activate the environment:

```zsh
conda activate local_file_organizer
```

### 4. Install and Run Ollama Ô∏è

This project now uses Ollama to run models locally via HTTP.

- Install Ollama: https://ollama.com/download
  - macOS: `brew install --cask ollama`
  - Linux: `curl -fsSL https://ollama.com/install.sh | sh`
  - Windows: Download and install from the website.
- Start the Ollama service (if it doesn't start automatically):
  ```bash
  ollama serve
  ```
- Pull the required models:
  ```bash
  ollama pull llama3.2:3b
  ollama pull llava:7b
  ```


### 5. Install Dependencies 

1. Ensure you are in the project directory:
   ```zsh
   cd path/to/Local-File-Organizer
   ```
   Replace `path/to/Local-File-Organizer` with the actual path where you cloned or extracted the project.

2. Install the required dependencies:
   ```zsh
   pip install -r requirements.txt
   ```

**Note:** If you encounter issues with any packages, install them individually:

```zsh
pip install Pillow pytesseract PyMuPDF python-docx
```

With the environment activated and dependencies installed, run the script using:

### 6. Running the Scriptüéâ
```zsh
python main.py
```

## Notes

- **Ollama Models:**
  - The script uses `llava:7b` (vision) and `llama3.2:3b` (text) via the local Ollama service at http://localhost:11434.
  - Ensure Ollama is running and these models are pulled (`ollama pull llava:7b` and `ollama pull llama3.2:3b`).
  - No external API keys are required; everything runs locally.


- **Dependencies:**
  - **pytesseract:** Requires Tesseract OCR installed on your system.
    - **macOS:** `brew install tesseract`
    - **Ubuntu/Linux:** `sudo apt-get install tesseract-ocr`
    - **Windows:** Download from [Tesseract OCR Windows Installer](https://github.com/UB-Mannheim/tesseract/wiki)
  - **PyMuPDF (fitz):** Used for reading PDFs.

- **Processing Time:**
  - Processing may take time depending on the number and size of files.
  - The script uses multiprocessing to improve performance.

- **Customizing Prompts:**
  - You can adjust prompts in `data_processing.py` to change how metadata is generated.

## License

This project is dual-licensed under the MIT License and Apache 2.0 License. You may choose which license you prefer to use for this project.

- See the [MIT License](LICENSE-MIT) for more details.